================================================================  Job Application  ===================================================================

Flow Diagram:

Browser ----> Controller(Job, Company, Review) -----> Services(Job, Company, Review) -----> Repository(Job, Company, Review) -----> Database (REQUEST)
Browser <-------------------------------------------------""" Server """---------------------------------------------------------- Database (RESPONSE)

======================================================================================================================================================

Project Setup:

	=> Use spring initializor to create project.
	=> Create required packages, the structure all depends on you, how you want to keep the structure. The controller,service,repository and class definition of one component in same package (following this one.). Other structure is keeping all component definitions,services,controllers and repositories in separate packages.
	=> @RestController for controllers, @Service for services, 
	=> As standards, definitions define class structure, services define business logic, repositories connect to db, controllers expose end-points to the client.
	=> Setup POSTMAN and create collections to group all the related API request in one collection.
	=> While creating service, divide that in two parts, to ensure loose coupling between the implementations. So create an interface with JobService, defining all the methods along with return types. Another class that will implement this interface for use in writing business logic.
	=> The generation of IDs should not be relied on user as they can provide null or duplicate ids. This can be managed through a class level static variable, in case you are not using database. So, initially when the DB is not there lets create an variable jobId to maintain id count.
	=> Rather than sending cold responses to any end-point wrap them into ResponseEntity<> Class to better handle the responses. It allows you to customize the responses, being flexible with your response handling, helps to maintain a consistent API design. So, keep return type of all end-points as ResponseEntity<TypeOfResponse>. return new ResponseEntity<>(typeObj,HttpStatus."status");
	=> Update/Put mapping can be successfully done in service list, either by updating each and every value except id, this will maintain order of your elements. Other way is you can remove record from list and add new record with id passed in url and create new entry. This will change the order of elements as new added item will be at last.
	=> @RequestMapping() : This annotation can be used at method level and class level both.
		Method-level : On method level it increases code as you have to define url for the end-point and also the method you want to execute. (value="url",method=RequestMapping.GET). On methods, specific mapping annotations are recommended as they provide more clarity and readability of the code.
		
		Class-level : On class level, this annotation is needed to add a base-url to all the mappings defined in particular controller. This will help to manage the end-points more efficiently. Recommended to be used.
======================================================================================================================================================

Part - 2 : Adding Database to application

What is JPA?
	Java Persistence API, used to create relational table in the database using the blueprint of the class. The advantages includes easy and Simple, makes query easier (no use of DMLs), allows to save and update objects and easy to integrate with Spring Boot.
	Dependency Spring Data JPA, will be our dependency which comes with ORM - object relational mapping. Auto-Map Class object with relational table in database.

Data Access Layer:
	The layer where all the repository classes reside. The CRUD operations on the database are handled by this layer.

How to create JpaRepository ------> JpaRepository<Entity-Name(Table class name), Primary-key-type> (public interface JobRepository extends JpaRepository<Job, Long> {
})

	H2 database ----> The in-memory database which is light-weight. Prefer to use in test environment only not in production, because auto-refresh with app restart.
Setup in application.properties file: 
	spring.h2.console.enabled=true
	spring.datasource.url=jdbc:h2:mem:testDB (testDB ===> database name)
	spring.jpa.show-sql=true (means all the sql queries generated by JPA should be logged in console.)
	spring.jpa.hibernate.ddl-auto=create-drop (indicates JPA to create tables on app start and delete tables on app stop.)
	spring.jpa.hibernate.ddl-auto=update (means update the table structures after start and stop of application)

Entities in JPA - An entity in JPA represents a table in database and each instance of an entity represents a row in the relational table.
@Entity --> annotation that is required to tell the JPA that should be mapped to a table. 
@Table(name = "custom_table") --> annotation required to provide a custom name to the table in database rather than same as class name.
@Id --> annotation to tell JPA that this variable should be used as primary key in table.
@GeneratedValue(strategy = ..) --> annotation that is used to tell JPA to auto-generate the id of the record according to defined strategy.

After creating repository instance add @Repository annotation on the interface to tell Spring to auto-wire it. In service implementation class now add a variable of repository to access the database. After doing so, start updating the service implementation class by making it dependant on Repository instance variable.

======================================================================================================================================================

Part - 3 : Adding components of the application

======================================================== Company Component ==================================================

Each company will have an id, a name, a description, a list jobs and a list of reviews. These list variables will have @OneToMany mapping with the company entity because there can be many jobs/reviews for a particular company. This one to many annotation will create a new table in the database which will define mapping of company id to job id. Add a list of reviews as variable along with annotation @OneToMany(mappedBy = "company") to make sure there are no separate tables.

We also need to add a company variable in our job model as it will be mapped to a company. At that variable @ManyToOne annotation will be added as many jobs will be mapped to one company. As of now, a new table was created for mapping of one to many annotation of company entity. To get rid of that table we can add a parameter to annotation like @OneToMany(mappedBy="company" *The variable name you kept in job entity*). This implies that in job entity we have this field which is mapping to this variable. An another annotation @JsonIgnore will be added with @OneToMany annotation so that infinite recursive calls for json objects can be avoided.

While creating a job, you have to pass an company object in json with id. If the company is not present it will throw an error. To handle that either create companies first, then add job. or keep error. Or if company object for id passed in job is null, create the company and then create job.


Similar to job component, create service,controller and repository for company component along with its class definition in a new company package.

================================================= Reviews Component for each company =========================================

Each review will have an id, a title, a description and a rating for the company. It will also have a company variable which will be mapped using @ManyToOne annotation, to make sure that review table in db have a Company_id column. Add @JsonIgnore annotation to void infinite recursive calls.

The end-points that will be used for rest-api calls, will be having "/companies/companyId/reviews", as reviews will be mapped to companies and can be fetched by company id. To get companies using id, we need company service in review service, therefore, we need to import that, because while creating a review we need to set company to that review.

While fetching a particular review with id, we need to first find all reviews for that company id, then from that list fetch out the review with your particular id.

Deleting a review is not that much simple. First you need to find the company with id, that it exists or not, then find review with that it exists or not. If both exists then find the review by id from repo, get its company and remove that review from the list of reviews in company. After deleting from company, save company through company service and also remove review by id from repo. After removing the review from company list also set company of review to null, to remove all references or links between company and review.

======================================================================================================================================================

====================================================== Spring Boot Actuator ==========================================================================

The Spring Boot Actuator gives you built-in production ready feautres to monitor and manage your aplication. Like a dashboard to help you monitor the health of your application, metrics related to your application, etc. It is important because it provides production ready features to help the developer get his application monitored. These features are provided using some end-points, these features are:
	1. Built-in end points
	2. Ability to view realtime metrics
	3. Customizable

----------------------------------------------- Setting up actuator in our application --------------------------------------------

1. Add a dependecy in your pom.xml for actuator.
2. Go to localhost:8080/actuator
		{
			"_links": {
				"self": {
					"href": "http://localhost:8080/actuator",
					"templated": false
					},
				"health": {
					"href": "http://localhost:8080/actuator/health",
					"templated": false
					},
				"health-path": {
					"href": "http://localhost:8080/actuator/health/{*path}",
					"templated": true
					}
				}
			}

These are by default end-points that are available. You can have more end-points by enabling them in application.properties file. To enable all the end-points you need to add this property to file.

		management.endpoints.web.exposure.include=*

Always remember, exposing all the end-points may lead to leak of some sensitive informationa bout the application, so use carefully.

3. Understanding actuator end-points:
	a. /health --> shows app health information, useful for checking status of application such as db connectivity, disk space, custom health checks
	b. /info --> display arbitrary information about the application, commonly used for displaying version, git commits, etc.
	c. /metrics --> shows metrics information that will help you to understand the performance and behavior of your running application.
	d. /loggers --> allows you to querying and modifying the log level of your application's loggers
	e. /beans --> provides you the list of all the Spring beans used in your application.
	f. /shutdown --> allows your app to gracefully shutdown.
	
4. Exploring major important end-points:
	
	/health ==> By default it provides only status of the application. To get more information you have to update the application.properties file and add this property "management.endpoint.health.show-details=always". Provides information about db, disk-space and ping status.
	
	/info ==> By default the info response will be blank because you have to enable that by the property "management.info.env.enabled=true". After that you have to add information about the application, by using properties with prefix info.app.name, info.app.description, info.app.version, info.git.repository, info.git.user, etc. after info.zzz, a new json object for zzz is created along with properties separated.
	
	/metrics ==> very powerful end-point which helps to monitor your application background and other things also. This is very useful in enterprise level applications.
	
	/loggers ==> very powerful end-point when it comes to production level because using this you can change log-levels directly from the end-point without stopping your application, that's why it is very important end-point. To change the log-level you have to send a post request to /logger/nameOfLogger with json body to update the values.
	
	/beans ==> gives list of all beans, can be used to get background understanding of the application that is running. Singleton scope means same bean object everytime it is requested. Prototype scope means new bean object whenever it is requested.
	
	/shutdown ==> this endpoint shuts your application down gracefully. This means that it will process all the queued requests first and then shutdown not abruptly. This is useful when you want to control your application from some external systems. And for security purpose it is disabled. You have to enable it and proper security measures should be taken after enabling that. The property to be enabled is "management.endpoint.shutdown.enabled=true". You can only trigger shutdown using post request. You can also add a property to conifrm graceful shutdown, i.e., "server.shutdown=graceful". URL will be /actuator/shutdown
	
======================================================================================================================================================

Spring Boot with Docker:
========================

Docker: an open-source platform that allows you to automate the deployment, scaling and management of applications using containerization. 

When a developer updates some library and push that code to shared code resources, it may cause conflict on some other developers code. To resolve that issue, the docker is used to containerize the application with the code and its dependecies. These containers can be moved from one machine to another, along with everything that is required to run that applications. These containers are light-weight images that are able to run on thier own, on all systems same way as on your system. The docker container contains code,runtime,libraries and other system tools required for application.

Docker architecture:
--------------------

Docker Engine 
-----------------
Docker CLI		|
Docker API		|
Docker Daemon <-|-----> Docker Container and Docker images <-----> Docker registery
-----------------
Host OS

Docker CLI and API interacts with Docker Daemon, that is responsible for building docker images and managing docker containers. The daemon do so with the help of host OS. Docker images are blueprints or templates that are used for creating docker containers. If you need to update docker container, you have to update the docker image. Then there is a docker registry that is responsible for storing and managing the docker images. The docker registry is a central repository for sharing docker images on different machines. These registries can be public/private.

Docker Concepts:
----------------
images : templates that defines the docker container and its dependecies.
containers : runtime environments created from docker images.
docker engine : the runtime that manages and runs the container.
docker file : a file that contains the instructions to build a Docker image.
docker hub : a cloud-based registry that hosts a vast collection of Docker images.

Docker Registry:
----------------
a storage and distribution system for name docker images. The features of docker registry includes: centralized resources, easy versioning and share your docker images. The official docker registry is docker hub, while each cloud platform have their own container registry. The google have that with name Artifact Registry.

Docker and Spring Boot:
-----------------------
To use docker with spring there are two ways. First is creating a docker file inside the main app folder and configuring all the required commands in that file. Other way is using the spring-boot-maven-plugin. Creating it using plugin is easy and quick.

Let's understand how this plugin works.
The cloud native buildpacks are the files which are compatible to be deployed to cloud platforms directly without using docker file. These standards are created by cnf cloud native foundation. So maven plugin gives cloud native application that are ready to deploy. It also have some layering concepts where your code,dependecies and runtime are cached in different layers, so when you update anything and rebuild only the changed layer will be rebuilt to make the process faster and efficient. Paketo buildpacks are the projects maintained by Spring Boot team to meet cloud native standards and specification, which makes the spring applications compatible with docker.

Advantages:
	- no docker file needed
	- sensible defaults
	- consistent environments
	- security
	- layering and efficiency
	- ease of use
	
Creating our first docker compatible image with spring boot maven plugin:
-------------------------------------------------------------------------

./mvnw spring-boot:build-image -Dspring-boot.build-image.imageName=<Image Name> ---- command to create docker images.

./mvnw - the maven wrapper which we will be using to create the docker image. Already included in project and a script that will be used to execute our commands.
spring-boot:build-image - maven goal provided by maven pulgin which will be responsible for creating cloud native build packs. First the app will be converted into jar file, then into an image.
-Dspring-boot.build-image.imageName=<Image Name> - this a system property that we are passing to the goal, that will be the image name. -D is a flag that represents that this is a system property.

Before running this command have an account on the docker hub. After that download docker desktop and make sure it is up and running. After that head to any terminal of your choice go to the root directory of your project and run the command.
--------------------------------------------------------------------------------------
./mvnw spring-boot:build-image "-Dspring-boot.build-image.imageName=username/anyname"|
--------------------------------------------------------------------------------------
The name of image must be all smalls.

After build is success, run docker login if you have not logged in docker. Then push your image to your repository, by using docker push arunantil0409/jobappimage. the repo name will be jobappimage.


Docker commands:
----------------

docker pull <image>
docker push <username/image>
docker run -it -d -p <host-port>:<container-port> --name <name> <image>
docker stop <container-id/container-name>
docker start <container-id/container-name>
docker rm <container-id/container-name>
docker rmi <image-id/image-name>
docker ps -> all running containers
docker ps -a -> all running and stopped containers
docker images -> list all images on host.
docker exec -it <container-id/container-name> bash -> to login to that container using cmd.
docker build -t <username/image> . -> used to create a docker image from docker file defined in the current directory, defined by .
docker logs <container-id/container-name>
docker inspect <container-id/container-name>


Running our Spring boot app from docker terminal:
-------------------------------------------------

docker run -p host-port:container-port <username/image>
docker run -d -p host-port:container-port <username/image>
----> after running this command you cannot use terminal. So to avoid that use -d flag also so that it can be ran as a new process. Host port is something you define that this port of my machine will interact with that port of container. like in our app we have 8080 in image, now I have choice on my machine where I want to run that on 8080 or anywhere else.

======================================================================================================================================================
Integrating PostgreSQL with your app:
=====================================

PostgreSQL is an open-source object relational dbms. It is popular for its SQL compliance, Extensibility, performance, strong community support and data integrity.

Adding and configuring PostgreSQL in our project:
-------------------------------------------------
From spring.io take dependency of postgresql and it to your pom.xml.
The configurations to be added in application.properties.
	spring.datasource.url=jdbc:postgresql://localhost:5432/jobappimage
	spring.datasource.username = usernameOfDB
	spring.datasource.password = password
	spring.jpa.database = POSTGRESQL
	spring.jpa.show-sql = true
	spring.jpa.hibernate.ddl-auto = create-drop      //means create table on session start and drop table on session stop.
	spring.jpa.database-platform = org.hibernate.dialect.PostgreSQLDialect
	
Docker Networks:
----------------
For postgresql we are going to use, two images one for postgreSQL and one for pgadmin. pgadmin is an open-source tool that is used to manage and monitor your db. The Docker network is the network through which two docker containers communicate. Try to use docker in your root directory because if you are creating images then you don't need to switch the directories or folders again and again.

--------------------------------------------------------------
docker run -d --name db -e POSTGRES_PASSWORD=password postgres|
--------------------------------------------------------------
--name --> to give name to the image.
-e --> to provide environment variables required for image
postgres --> image name we want.

-------------------------------------------------------------------------------------------------------------------------
docker run -d --name pgadmin -e PGADMIN_DEFAULT_EMAIL=admin@admin.com -e PGADMIN_DEFAULT_PASSWORD=admin dpage/pgadmin4 |
-------------------------------------------------------------------------------------------------------------------------
docker exec -it pgadmin ping db | -it flag tells to execute this command in interactive console of pgadmin and command is ping db.
---------------------------------
docker rm -f db pgadmin | remove docker containers with these names.
-------------------------

Configuring docker network:
___________________________
a. Create network : docker network create network-name.
b. Run same commands to run image containers but this time with --network network-name flag with both images.
		docker run -d --name db --network my-network -e POSTGRES_PASSWORD=password postgres
		docker run -d --name pgadmin --network my-network -e PGADMIN_DEFAULT_EMAIL=admin@admin.com -e PGADMIN_DEFAULT_PASSWORD=admin dpage/pgadmin4
		docker exec -it pgadmin ping db
c. This time ping command will succeed as now they are on the same network.

Setting up postgres and pgadmin for project:
--------------------------------------------

------------------------------------------------------------------------------------------------------------------------------------------------------
docker run -d --name postgres_container -e POSTGRES_USER=user -e POSTGRES_PASSWORD=password -e PGDATA=/data/postgres -v postgres:/data/postgres -p 5432:5432 --network postgres_net --restart unless-stopped postgres
------------------------------------------------------------------------------------------------------------------------------------------------------
docker run -d --name pgadmin_container -e PGADMIN_DEFAULT_EMAIL=pgadmin4@pgadmin.com -e PGADMIN_DEFAULT_PASSWORD=admin -e PGADMIN_CONFIG_SERVER_MODE=false -v pgadmin:/var/lib/pgadmin -p 5050:80 --network postgres_net --restart unless-stopped dpage/pgadmin4
------------------------------------------------------------------------------------------------------------------------------------------------------
If you have an ecosystem with large number of containers, running that much commands will be very difficult. Therefore to make that process better, use docker-compose.yaml file. This file should be created in root folder with same name and add the above defined properties of container in this file. Sample file will look like:

services:
  postgres:
    container_name: postgres_container
    image: postgres
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
      PGDATA: /data/postgres
    volumes:
      - postgres:/data/postgres
    ports:
      - "5432:5432"
    networks:
      - postgres-network
    restart: unless-stopped

  pgadmin:
    container_name: pgadmin_container
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-pgadmin4@pgadmin}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    ports:
      - "5050:80"
    networks:
      - postgres-network
    restart: unless-stopped

volumes:
  postgres:
  pgadmin-data:

networks:
  postgres-network:

======> Note: Do not use docker plugin of IntelliJ to run this. It will give errors only. This file is okay.

Creating database using pgadmin:
--------------------------------
a. Head over to browser and run localhost:5050 defined in the compose file, to go to pgadmin dashboard.
b. After logging, create a head password, 12345 for me right now. Add new server add hostname as postgres that you kept in service-name in docker-compose file.
c. Create database with the same name defined in your application.properties file.
d. Once you complete this set-up run the application and see that tables are created in your database or not.
e. Right click on table edit/view data to have a tab for SQL on your table.
f. Test the database connectivity by running rest APIs.

======================================================================================================================================================